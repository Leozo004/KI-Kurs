{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ffbc0d4-58dc-4e06-9205-7f84c589c264",
   "metadata": {},
   "source": [
    "# 1. Künstliche Intelligenz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4c9814-9c57-4641-9d68-97b4631849dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Inhalt\n",
    "\n",
    "- Unterschied starke & schwache KI\n",
    "- Deep Learning & PyTorch\n",
    "    - Code schwaches neuronales Netzwerk\n",
    "    - Code starkes neuronales Netzwerk\n",
    "- praktische Anwendungsfälle Künstlicher Intelligenz\n",
    "    - Vorhersage von Um- und Absatz\n",
    "    - Anomalie-, Fehler und Ausreißererkennung\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bc7e2b-1b43-4ae0-908d-5520d7bfaf26",
   "metadata": {},
   "source": [
    "### Unterschied starke & schwache Intelligenz\n",
    "\n",
    "Eine starke KI ist zur Zeit noch reinste Fiktion, da eine starke KI menschlich denken und fühlen kann. Davon sind wir noch Jahrzehnte entfernt. Bei der schwachen KI hingegen handelt es sich nur um Algorithmen, welche nicht selbstständig “denken” können."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594a4179-65a0-49a4-84e4-2f381358e0ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Deep Learning\n",
    "\n",
    "Deep Learning stellt den Grundbaustein heutiger KI-Systeme dar, \n",
    "da dieses menschliches Lernen und, mit Hilfe neuronaler Netze, ein Gehirn imitiert. \n",
    "Beim Lernvorgang ist ein Eingriff menschlicher Seite nicht nötig, \n",
    "nur die Daten müssen zur Verfügung gestellt werden. Beim Deep Learning werden \n",
    "große Mengen von Daten benötigt. PyTorch wird für die Entwicklung neuronaler Netze genutzt, \n",
    "PyTorch ist ein Opensource Framework, welches vor allem durch seine Benutzerfreundlichkeit und Flexibilität zu einem der führenden Frameworks wurde. \n",
    "Es gibt 3 Arten von neuronalen Netzwerken:\n",
    "Underfitting Netzwerke\n",
    "Generalisation\n",
    "Overfitting Netzwerke\n",
    "Nachführend sind 2 Beispiele für ein gutes und ein schlechtes neuronales Netzwerk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c693c57-b9ae-4c42-92ba-86a1586b779a",
   "metadata": {},
   "source": [
    "#### Code für schwaches neuronales Netzwerk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c639179-b8a6-429f-a3b3-036b50c21c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim from torchvision\n",
    "import datasets, transforms \n",
    "\n",
    "# Datenvorbereitung \n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]) \n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True) \n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True) \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=128, shuffle=True) \n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Einfaches, schlechtes Modell \n",
    "class SimpleNet(nn.Module): \n",
    "    def __init__(self): \n",
    "        super(SimpleNet, self).__init__() \n",
    "        self.fc1 = nn.Linear(28*28, 10) # Nur 10 Neuronen \n",
    "\n",
    "    def forward(self, x): \n",
    "        x = x.view(-1, 28*28) \n",
    "        x = torch.relu(self.fc1(x)) \n",
    "        return x \n",
    "\n",
    "        # Modell, Loss und Optimizer initialisieren \n",
    "        model = SimpleNet() \n",
    "        criterion = nn.CrossEntropyLoss() \n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001) \n",
    "\n",
    "    # Training \n",
    "    def train(model, train_loader, criterion, optimizer, epochs=5): \n",
    "        for epoch in range(epochs): \n",
    "            for images, labels in train_loader: \n",
    "                outputs = model(images) \n",
    "                loss = criterion(outputs, labels) \n",
    "\n",
    "                optimizer.zero_grad() \n",
    "                loss.backward() \n",
    "                optimizer.step() \n",
    "                print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}') \n",
    "\n",
    "    # Testen \n",
    "    def test(model, test_loader): \n",
    "        correct = 0 \n",
    "        total = 0 \n",
    "    with torch.no_grad(): \n",
    "        for images, labels in test_loader: \n",
    "            outputs = model(images) \n",
    "            _, predicted = torch.max(outputs.data, 1) \n",
    "            total += labels.size(0) \n",
    "            correct += (predicted == labels).sum().item() \n",
    "        print(f'Test Accuracy: {100 * correct / total:.2f}%') \n",
    "\n",
    "    # Trainieren und Testen \n",
    "    train(model, train_loader, criterion, optimizer) \n",
    "    test(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5cc53a-4b79-4f11-9e4e-b27ca65370ae",
   "metadata": {},
   "source": [
    "#### Code starkes neuronales Netzwerk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df75de6a-4497-4c6c-afa2-118c2b275256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim from torchvision \n",
    "import datasets, transforms \n",
    "\n",
    "# Datenvorbereitung \n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]) \n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True) \n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True) \n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=128, shuffle=True) \n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=128, shuffle=False) \n",
    "\n",
    "# Gutes Modell mit mehreren Schichten \n",
    "class GoodNet(nn.Module): \n",
    "    def __init__(self): \n",
    "        super(GoodNet, self).__init__() \n",
    "        self.fc1 = nn.Linear(28*28, 512) \n",
    "        self.fc2 = nn.Linear(512, 256) \n",
    "        self.fc3 = nn.Linear(256, 10) \n",
    "        self.dropout = nn.Dropout(0.2) # Dropout zur Regularisierung \n",
    "\n",
    "    def forward(self, x): \n",
    "        x = x.view(-1, 28*28) \n",
    "        x = torch.relu(self.fc1(x)) \n",
    "        x = self.dropout(x) x = torch.relu(self.fc2(x)) \n",
    "        x = self.fc3(x) \n",
    "        return x \n",
    "\n",
    "    # Modell, Loss und Optimizer initialisieren \n",
    "    model = GoodNet() criterion = nn.CrossEntropyLoss() \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001) \n",
    "\n",
    "    # Training \n",
    "    def train(model, train_loader, criterion, optimizer, epochs=10): \n",
    "        for epoch in range(epochs): \n",
    "            for images, labels in train_loader: \n",
    "                outputs = model(images) \n",
    "                loss = criterion(outputs, labels) \n",
    "\n",
    "                optimizer.zero_grad() \n",
    "                loss.backward() \n",
    "                optimizer.step() \n",
    "\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}') \n",
    "\n",
    "    # Testen \n",
    "    def test(model, test_loader): \n",
    "        correct = 0 \n",
    "        total = 0 \n",
    "        with torch.no_grad(): \n",
    "            for images, labels in test_loader: \n",
    "                outputs = model(images) \n",
    "                _, predicted = torch.max(outputs.data, 1) \n",
    "                total += labels.size(0) \n",
    "                correct += (predicted == labels).sum().item() print(f'Test Accuracy: {100 * correct / total:.2f}%') \n",
    "\n",
    "    # Trainieren und Testen \n",
    "    train(model, train_loader, criterion, optimizer) \n",
    "    test(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f93160-50a8-42f5-a76a-eb8621f0205f",
   "metadata": {},
   "source": [
    "### praktische Anwendungsfälle Künstlicher Intelligenz\n",
    "\n",
    "KI wird heute in vielen Bereichen genutzt, einige von diesen werden hier näher erleutert. Viele dieser Fallbeispiele können für Sie interessant sein. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf8bc40-706b-4c0a-8d33-fcd638ab8d1e",
   "metadata": {},
   "source": [
    "#### Vorhersage von Um- & Absatz\n",
    "\n",
    "Vorhersage von KPIs(Key Performance Indiators) -> wichtig für Absatz ->\n",
    "für strategische Unternehmensführung etc. erforderlich\n",
    "Einsatz von Zeitreihenanalysen oder künstlicher neuronaler Netze-> \n",
    "zur Vorhersage des Werts, durch historischer Daten\n",
    "Berücksichtigung vieler Faktoren "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681da28d-5163-47e2-947f-eeca3528bcff",
   "metadata": {},
   "source": [
    "#### Anomalie-, Fehler und Ausreißererkennung\n",
    "\n",
    "Erkennung von Betrugsversuchen\n",
    "zusätzliche nicht menschliche Validierung einführen -> \n",
    "Fälle die übersehen wurden etc.\n",
    "dies erlaubt Gegenmaßnahmen oder Kontrollen durchzuführen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d42e30-8ee3-44ea-a65c-bc67b2448535",
   "metadata": {},
   "source": [
    "#### Erkennung personenbezogener Daten\n",
    "\n",
    "schwierig Überblick, bei vielen Datenbanken, zu behalten -> KI überprüft diese schnell auf personenbezogene Daten\n",
    "somit kann man dann überprüfen ob, wenn solche Daten drin sind, ob die da hingehören und dann bereinigen oder auch nicht"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529cfca3-a866-42ab-b9c8-cc3127e1931f",
   "metadata": {},
   "source": [
    "#### Meetings mitschreiben\n",
    "\n",
    "otter.ai & meetgeek -> KI-Dienste\n",
    "Aufzeichnung, Transkribierung und Aufstellung eines übersichtlichen Protokolls\n",
    "innerhalb kürzester Zeit Gesprächsprotokolle für alle Parteien\n",
    "meist objektiver und hört genau zu\n",
    "mittels Grain können Datenbanken für Kundenfeedback etc. erstellt werden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9875f0-25a4-4dda-9a12-50f77646b42e",
   "metadata": {},
   "source": [
    "#### Übersetzungen\n",
    "\n",
    "Textübersetzung von DeepL \n",
    "Whisper von OpenAI kann Videocalls synchron transkribieren und Untertitel erzeugen\n",
    "Auri für E-Mail-VerkehrChatGPT zum lokalisieren von Websites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085c4c07-4f63-4c42-bdd8-5265be6009ed",
   "metadata": {},
   "source": [
    "#### Kundenchat/Support\n",
    "\n",
    "Chatbot, durch Firmendaten trainiert, 24/7 erreichbar und teilweise fast nicht mehr von Mensch unterscheidbar\n",
    "Anbieter:\n",
    "Mottle\n",
    "Webapi \n",
    "Intercom\n",
    "bieten Möglichkeiten Chatbots Eigens zu erstellen ->\n",
    "dadurch Auslastung des Supports verringern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e9e898-022f-47e6-9f9d-a660f2a64b18",
   "metadata": {},
   "source": [
    "#### KI-Analyse & Automatisierung\n",
    "\n",
    "KI-Systeme können tausende von Daten im Überblick behalten und machen es Datenanalysten leichter\n",
    "KIs geben diese verständlich strukturiert aus\n",
    "Autopia & Timeto liefern Projektmanagement-Tools:\n",
    "erstellt Zeitpläne\n",
    "plant Meetings\n",
    "übernimmt viele, kleinere Datenbasierte Aufgaben\n",
    "Canopy bietet:\n",
    "automatische Auswertung von Maschinen, Generatoren und \n",
    "anderen Anlagen\n",
    "Verkürzung von Ausfallzeiten \n",
    "Steigerung Maschinenauslastung\n",
    "KIs wie Olli:\n",
    "Nutzung ähnlicher Daten für Marketing, Verkauf und andere Felder\n",
    "Verbesserung der Verfügbarkeit\n",
    "Verständlichkeit von Daten\n",
    "Ermöglichung schnellerer und besserer Entscheidungen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c67133e-c4f8-47ca-8e17-4ba713e525d5",
   "metadata": {},
   "source": [
    "#### Jobausschreibung\n",
    "\n",
    "Hilfe bei Ausschreibungstexten durch:\n",
    "ChatGPT\n",
    "Bing-Chatbot\n",
    "Erleichterung durch asynchrone Videobewerbungen \n",
    "Turbohire:\n",
    "Jobausschreibung\n",
    "Vergleich eingesendeter Bewerbungen\n",
    "Vorauswahl anhand ihrer Vorgaben\n",
    "Terminplanung der Gespräche\n",
    "Unterstützung beim OnBoarding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0afd0a-1f03-4fe7-b3d1-1a6b5a49b4f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
